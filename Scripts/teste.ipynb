{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: torch.Size([8718080, 448])\n",
      "y size: torch.Size([8718080])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# variables\n",
    "\n",
    "EPOCHS = 100\n",
    "LR = 0.0001\n",
    "BATCH_SIZE = 1024  # X size (8705536 descriptors, 448 features (from vgg11))\n",
    "GRADIENT_CLIPPING_VALUE = 0.5\n",
    "#MODEL_VERSION = 'model_0' if len(os.listdir(\"./models\")) == 0 else f'model_{len(os.listdir(\"./models\"))}'\n",
    "CHECKPOINT_PATH = \"./checkpoints/model_1/model_1_epoch_2000\"#f\"./checkpoint/{MODEL_VERSION}/{MODEL_VERSION}_epoch_2000\"\n",
    "\n",
    "\n",
    "# loads data and splits into training and testing\n",
    "X = torch.cat([torch.load(f\"../descriptors/sample_{i}\") for i in range(int(len(os.listdir(\"../descriptors\")) / 2))], dim=0)\n",
    "y = torch.cat([torch.load(f\"../descriptors/sample_{i}_anotation\") for i in range(int(len(os.listdir(\"../descriptors\")) / 2))], dim=0)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, y_train = X, y\n",
    "\n",
    "print(f\"X size: {X.size()}\")\n",
    "print(f\"y size: {y.size()}\")\n",
    "\n",
    "# makes batchers for training\n",
    "train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=BATCH_SIZE)\n",
    "\n",
    "#model definition\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=448, out_features=256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=256, out_features=128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=128, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=32, out_features=1)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=LR)\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch).squeeze(1) \n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIPPING_VALUE)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, loss_fn):\n",
    "    model.eval()  # change model to evaluation mode\n",
    "    partial_loss = []\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for X_batch, y_batch in data_loader:\n",
    "  \n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            partial_loss.append(loss.item())\n",
    "            total_loss += loss.item() * X_batch.size(0)  \n",
    "\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            correct_predictions += (predicted == y_batch).sum().item()\n",
    "            total_samples += X_batch.size(0)\n",
    "    \n",
    "    average_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    return average_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 176470.17323072028\n",
      "Epoch 2, Loss: 176066.82388521446\n",
      "Epoch 3, Loss: 175636.83740412162\n",
      "Epoch 4, Loss: 175193.39466863286\n",
      "Epoch 5, Loss: 174764.5318259198\n",
      "Epoch 6, Loss: 174374.69021450882\n",
      "Epoch 7, Loss: 174000.5313901285\n",
      "Epoch 8, Loss: 173645.1139646337\n",
      "Epoch 9, Loss: 173278.1671161002\n",
      "Epoch 10, Loss: 172924.88746365276\n",
      "Epoch 11, Loss: 172557.23163164392\n",
      "Epoch 12, Loss: 172175.51114991654\n",
      "Epoch 13, Loss: 171856.76444436688\n",
      "Epoch 14, Loss: 171541.23368643684\n",
      "Epoch 15, Loss: 171220.69418850756\n",
      "Epoch 16, Loss: 170931.2090096235\n",
      "Epoch 17, Loss: 170675.60344399078\n",
      "Epoch 18, Loss: 170440.58496342506\n",
      "Epoch 19, Loss: 170190.59221080504\n",
      "Epoch 20, Loss: 169959.12842051726\n",
      "Epoch 21, Loss: 169744.36028310764\n",
      "Epoch 22, Loss: 169511.25905780646\n",
      "Epoch 23, Loss: 169264.60337249635\n",
      "Epoch 24, Loss: 169026.3517999091\n",
      "Epoch 25, Loss: 168821.40524118865\n",
      "Epoch 26, Loss: 168642.43254961798\n",
      "Epoch 27, Loss: 168482.94100462162\n",
      "Epoch 28, Loss: 168332.76279160738\n",
      "Epoch 29, Loss: 168179.03857935878\n",
      "Epoch 30, Loss: 168012.1696740783\n",
      "Epoch 31, Loss: 167826.00234869216\n",
      "Epoch 32, Loss: 167641.0888175364\n",
      "Epoch 33, Loss: 167459.76788518977\n",
      "Epoch 34, Loss: 167293.84329136173\n",
      "Epoch 35, Loss: 167148.2895750333\n",
      "Epoch 36, Loss: 167000.86584835398\n",
      "Epoch 37, Loss: 166862.07511515458\n",
      "Epoch 38, Loss: 166740.77685556552\n",
      "Epoch 39, Loss: 166612.07932661977\n",
      "Epoch 40, Loss: 166468.57987993996\n",
      "Epoch 41, Loss: 166323.648863574\n",
      "Epoch 42, Loss: 166181.78725030285\n",
      "Epoch 43, Loss: 166049.89979785492\n",
      "Epoch 44, Loss: 165932.49760042728\n",
      "Epoch 45, Loss: 165808.606940336\n",
      "Epoch 46, Loss: 165690.53274841883\n",
      "Epoch 47, Loss: 165569.4453681729\n",
      "Epoch 48, Loss: 165450.705205683\n",
      "Epoch 49, Loss: 165336.95377151817\n",
      "Epoch 50, Loss: 165219.30386836434\n",
      "Epoch 51, Loss: 165101.31146286475\n",
      "Epoch 52, Loss: 164951.90273832428\n",
      "Epoch 53, Loss: 164818.5643225955\n",
      "Epoch 54, Loss: 164691.5172887887\n",
      "Epoch 55, Loss: 164566.42536490408\n",
      "Epoch 56, Loss: 164443.92280934186\n",
      "Epoch 57, Loss: 164317.83139003676\n",
      "Epoch 58, Loss: 164191.46842918906\n",
      "Epoch 59, Loss: 164065.95635952096\n",
      "Epoch 60, Loss: 163941.0086488193\n",
      "Epoch 61, Loss: 163816.35812477933\n",
      "Epoch 62, Loss: 163694.01729928917\n",
      "Epoch 63, Loss: 163575.0154668061\n",
      "Epoch 64, Loss: 163459.59480496586\n",
      "Epoch 65, Loss: 163348.1939636044\n",
      "Epoch 66, Loss: 163239.49135474899\n",
      "Epoch 67, Loss: 163127.80234689065\n",
      "Epoch 68, Loss: 163014.63977887022\n",
      "Epoch 69, Loss: 162906.36222017452\n",
      "Epoch 70, Loss: 162799.6246201558\n",
      "Epoch 71, Loss: 162694.84423220748\n",
      "Epoch 72, Loss: 162591.0186022704\n",
      "Epoch 73, Loss: 162487.7622803161\n",
      "Epoch 74, Loss: 162384.726071819\n",
      "Epoch 75, Loss: 162288.30838462897\n",
      "Epoch 76, Loss: 162169.55454265443\n",
      "Epoch 77, Loss: 162051.8167169171\n",
      "Epoch 78, Loss: 161936.39855534432\n",
      "Epoch 79, Loss: 161817.41283224983\n",
      "Epoch 80, Loss: 161695.9739750707\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#training          \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m actual_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_epoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_loader, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n\u001b[0;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGRADIENT_CLIPPING_VALUE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\leand\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), ([grads], _)) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training          \n",
    "for actual_epoch in range(EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, loss_fn)\n",
    "    \n",
    "    print(f\"Epoch {actual_epoch + 1}, Loss: {train_loss}\")\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, loss_fn):\n",
    "    model.eval()  # change model to evaluation mode\n",
    "    partial_loss = []\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for X_batch, y_batch in data_loader:\n",
    "  \n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            partial_loss.append(loss.item())\n",
    "            total_loss += loss.item() * X_batch.size(0)  \n",
    "\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            correct_predictions += (predicted == y_batch).sum().item()\n",
    "            total_samples += X_batch.size(0)\n",
    "    \n",
    "    average_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    return partial_loss, average_loss, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
